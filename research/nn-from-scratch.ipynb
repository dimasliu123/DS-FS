{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b11307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153bc924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "perturbation learning -> inspired by perturbation theory, \n",
    "study of small changes in a system which can be result of \n",
    "interacting with the system,  \n",
    "the inspiration in neural network is to add some gaussian noise to the network, so the \n",
    "model is more robust during training, it can also helps avoiding overfitting \n",
    "\n",
    "gamma : parameter => default = 0.55\n",
    "eta : learning_rate => default = 0.01\n",
    "\"\"\"\n",
    "\n",
    "def decay_var(eta : float =0.01, gamma : float =0.55):\n",
    "    return eta / ( ( 1 + w ) ** gamma )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd55c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "hebbian learning -> also called local learning, unlike backpropagation, it's weight update is not dependent on\n",
    "other weights or layer of N + 1, instead, each weights learns independently\n",
    "it is popular on unsupervised learning to find the patterns of in it's environment (mostly data)\n",
    "update w => w_new = w_new + ∆w\n",
    "∆w -> ß * x * y\n",
    "\"\"\"\n",
    "print(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1091ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    y_ohe = np.zeros((len(y), len(np.unique(y))))\n",
    "    y_ohe[np.arange(len(y)), y] = 1\n",
    "    return y_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63dd1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "y_ohe = one_hot(y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_ohe, test_size=0.10, random_state=42)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "sc_train = sc.transform(X_train)\n",
    "sc_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75df9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z, derivative=False):\n",
    "    if derivative:\n",
    "        z[z<=0] = 0 \n",
    "        z[z>0] = 1\n",
    "        return z\n",
    "    else : \n",
    "        return np.maximum(0, z)\n",
    "\n",
    "def sigmoid(z, derivative=False):\n",
    "    if derivative :\n",
    "        return (1 / ( 1 + np.exp(-z)) ) - (1 - (1 / ( 1 + np.exp(-z) ) ) )\n",
    "    else : \n",
    "        return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed347fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1 layer_in, 1 h_layer, 1 out_layer\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1 layer_in, 1 h_layer, 1 out_layer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83a0c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "W1 = np.random.normal(loc=0., scale=0.05, size=(X.shape[1], 32)) * np.sqrt(X.shape[1] / 32)\n",
    "b1 = np.random.normal(loc=0., scale=0.05, size=(1, 32)) * np.sqrt(X.shape[1] / 32)\n",
    "\n",
    "W2 = np.random.normal(loc=0., scale=0.05, size=(32, 16)) * np.sqrt(32 / 16)\n",
    "b2 = np.random.normal(loc=0., scale=0.05, size=(1, 16)) * np.sqrt(32 / 16)\n",
    "\n",
    "W3 = np.random.normal(loc=0., scale=0.05, size=(16, y_ohe.shape[1])) * np.sqrt(16 / y_ohe.shape[1])\n",
    "b3 = np.random.normal(loc=0., scale=0.05, size=(1, y_ohe.shape[1])) * np.sqrt(16 / y_ohe.shape[1])\n",
    "\n",
    "nn = {}\n",
    "nn['W1'] = W1\n",
    "nn['b1'] = b1\n",
    "nn['W2'] = W2\n",
    "nn['b2'] = b2\n",
    "nn['W3'] = W1\n",
    "nn['b3'] = b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "231e7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffn \n",
    "Z1 = np.dot(sc_train, W1) + b1\n",
    "A1 = relu(Z1)\n",
    "\n",
    "Z2 = np.dot(A1, W2) + b2\n",
    "A2 = relu(Z2)\n",
    "\n",
    "Z3 = np.dot(A2, W3) + b3\n",
    "y_hat = sigmoid(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bddc2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f2a4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# backprop\n",
    "dW1 = (1 / len(y_train)) * np.dot(A2.T, (y_hat - y_train))\n",
    "db1 = (1 / len(y_train)) * np.sum(y_hat - y_train) \n",
    "dA1 = sigmoid(dW1, derivative=True)\n",
    "\n",
    "dW2 = (1 / len(y_train)) * np.dot(A1.T, (y_hat - y_train))\n",
    "db2 = (1 / len(y_train)) * np.sum(y_hat - y_train)\n",
    "dA1 = relu(dW2, derivative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f3cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear :\n",
    "    def __init__(self, \n",
    "                 inNodes : int, \n",
    "                 outNodes : int, \n",
    "                 use_bias : bool =True,\n",
    "                 w_init : str = \"uniform\"):\n",
    "        self.inNodes = inNodes\n",
    "        self.outNodes = outNodes\n",
    "        self.use_bias = use_bias\n",
    "        self.w_init = w_init.lower()\n",
    "        if self.use_bias : \n",
    "            if self.w_init == \"normal\":\n",
    "                w = np.random.normal(loc=0., scale=0.05, size=(self.inNodes, self.outNodes))\n",
    "                b = np.random.normal(loc=0., scale=0.05, size=((self.outNodes)))\n",
    "                self.w, self.b = w, b\n",
    "            elif w_init == \"uniform\":\n",
    "                w = np.random.uniform(low=-0.05, high=0.05, size=(self.inNodes, self.outNodes))\n",
    "                b = np.random.uniform(low=-0.05, high=0.05, size=((self.outNodes)))\n",
    "                self.w, self.b = w, b\n",
    "            elif w_init == \"he_normal\":\n",
    "                w = np.random.normal(loc=0., scale=0.05, size=(self.inNodes, self.outNodes)) * np.sqrt(2 / self.inNodes)\n",
    "                b = np.random.normal(loc=0., scale=0.05, size=(self.inNodes, self.outNodes)) * np.sqrt(2 / self.inNodes)\n",
    "                self.w, self.b = w, b\n",
    "            elif w_init == \"he_uniform\":\n",
    "                limits = np.sqrt(6 / self.inNodes)\n",
    "                w = np.random.uniform(low=-limits, high=limits, size=(self.inNodes, self.outNodes))\n",
    "                b = np.random.uniform(low=-limits, high=limits, size=(self.outNodes))\n",
    "                self.w, self.b = w, b\n",
    "            else :\n",
    "                raise ValueError(\"Weights initializer is not valid\")\n",
    "        else : \n",
    "            if self.w_init == \"normal\":\n",
    "                w = np.random.normal(loc=0., scale=0.05, size=(self.inNodes, self.outNodes))\n",
    "                self.w = w\n",
    "            elif w_init == \"uniform\":\n",
    "                w = np.random.uniform(low=-0.05, high=0.05, size=(self.inNodes, self.outNodes))\n",
    "                self.w = w\n",
    "            elif w_init == \"he_normal\":\n",
    "                w = np.random.normal(loc=0., scale=0.05, size=(self.inNodes, self.outNodes)) * np.sqrt(2 / self.inNodes)\n",
    "                self.w = w\n",
    "            elif w_init == \"he_uniform\":\n",
    "                limits = np.sqrt(6 / self.inNodes)\n",
    "                w = np.random.uniform(low=-limits, high=limits, size=(self.inNodes, self.outNodes))\n",
    "                self.w = w \n",
    "            else :\n",
    "                raise ValueError(\"Weights initializer is not valid\")\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.use_bias:\n",
    "            self.out = np.matmul(inputs, self.w) + self.b\n",
    "        else :\n",
    "            self.out = np.matmul(inputs, self.w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4037257",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Linear(sc_train.shape[1], 16)\n",
    "x2 = Linear(16, 8)\n",
    "out = Linear(8, y_ohe.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9162882",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.matmul(sc_train, x1.w)\n",
    "z2 = np.matmul(z1, x2.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a23b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
